# Sistema de Afiliaci√≥n Autom√°tica mediante OCR de INE

## ü™™ Descripci√≥n general

Este proyecto implementa un sistema completo para la extracci√≥n autom√°tica de datos de credenciales INE a partir de im√°genes o PDFs.
El pipeline utiliza:

YOLOv8 (modelo entrenado) para detectar la tarjeta INE en la imagen.

Correcci√≥n de perspectiva para normalizar la tarjeta.

Preprocesamiento avanzado de OCR (denoise, contraste, escalado).

Tesseract OCR para extraer texto.

Parser especializado que estructura la informaci√≥n en campos como:

apellido paterno

apellido materno

nombres

direcci√≥n

CURP

fecha de nacimiento

vigencia

sexo

El sistema fue dise√±ado para integrarse a un CRM que realiza afiliaci√≥n de clientes, reduciendo tiempo de captura y errores manuales.

## Arquitectura del Sistema

           üì§ Imagen/PDF (INE)
                   ‚îÇ
                   ‚ñº
       1. YOLOv8: detecci√≥n de credencial
                   ‚îÇ (m√∫ltiples candidatos)
                   ‚ñº
     2. Warp + normalizaci√≥n de perspectiva
                   ‚îÇ
                   ‚ñº
        3. Preprocesamiento OCR:
           - Denoise avanzado
           - CLAHE (contraste local)
           - Super-resize (escalado)
                   ‚îÇ
                   ‚ñº
           4. Tesseract OCR
                   ‚îÇ
                   ‚ñº
         5. Parser especializado INE
                   ‚îÇ
                   ‚ñº
     6. Selecci√≥n del "mejor resultado"
         (scoring de campos detectados)
                   ‚îÇ
                   ‚ñº
           üì¶ JSON estructurado

## Requerimientos
* Python 3.11
* Tesseract OCR (con idioma espa√±ol)
* Poppler (solo si se procesan PDFs)
* Bibliotecas Python:
* ultralytics
* opencv-python
* numpy
* pdf2image
* pytesseract
* fastapi
* uvicorn
* pydantic
* pillow


## Flujo interno del procesamiento
1. Detecci√≥n de INE con YOLOv8

El sistema ejecuta YOLO sobre la imagen completa y obtiene todas las detecciones posibles (candidatos).
Para cada candidato:

* recorta el bounding box,

* aplica un peque√±o margen,

* ejecuta un warp de perspectiva,

* prepara la imagen para OCR.

Esto permite fallback autom√°tico si la detecci√≥n principal fue incorrecta.

2. Preprocesamiento para OCR

Se aplica:

* Conversi√≥n a grises

* Denoising adaptado

* CLAHE (aumento de contraste local)

* Upscaling 3√ó con interpolaci√≥n c√∫bica

El objetivo es maximizar legibilidad de texto antes de mandarlo a Tesseract.

3. OCR con Tesseract
Se usa configuraci√≥n optimizada. Y se ajusta din√°micamente por zonas m√°s delicadas (nombre, CURP, clave).

```    
--oem 3      # LSTM (OCR moderno)

--psm 6      # Bloques de texto semi-estructurados
```


4. Parser de campos

El parser:

* normaliza el texto

* limpia ruido y caracteres basura

Encuentra secciones:

- Nombre Completo (Apellido Paterno / Materno / Nombre(s))
- Sexo
- Domicilio (CALLE / AV / COL / CP)
- C√≥digo Postal
- CURP (Con Validaci√≥n)
- Clave de Elector
- Fecha de nacimiento
- Vigencia
- Secci√≥n


Extrae nombre completo usando heur√≠sticas robustas:

- ignora tokens muy cortos,
- permite nombres compuestos,
- tolera errores de OCR.

Tambi√©n infiere:

- sexo y fecha de nacimiento desde la CURP (si OCR falla).

Finalmente  el parser genera una salida en formato Json:

```
{
  "apellido_paterno": "...",
  "apellido_materno": "...",
  "nombres": "...",
  "nombre_completo": "...",
  "domicilio": "...",
  "curp": "...",
  "clave_elector": "...",
  "fecha_nacimiento": "YYYY-MM-DD",
  "vigencia": "YYYY-YYYY"
}
```

## Entrega de la API
Se entrega el siguiente contrato con la llamada de la API, que se pueden modificar directamente de los datos extra√≠dos del parser.

```
 data = INEData(
            apellido_paterno,
            apellido_materno,
            nombres,
            sexo,
            direccion,
            codigo_postal,
            curp,
            fecha_nacimiento,
            curp_validada,
            clave_elector,
            seccion=,
            vigencia=
        )

        meta = INEMeta(
            request_id,
            score,
            parser_version=,
            processing_ms,
            warnings,
        )
```

## Selecci√≥n del mejor candidato
Si YOLO produjo varias detecciones:

* cada recorte se procesa,
* cada resultado se ‚Äúpunt√∫a‚Äù seg√∫n:
* n√∫mero de campos v√°lidos,
* calidad del texto,
* presencia de CURP / clave elector,
* coherencia de nombre y domicilio.

Se elige el resultado con mayor score.

## C√≥mo ejecutar localmente

Ejecutar la API

```
uvicorn app.app:app --reload --host 0.0.0.0 --port 8000 
```
Hacer una prueba con curl:
```
curl -X POST "http://127.0.0.1:8000/api/ine/parse" \
  -F "file=@imagenes_prueba/IneAdan.pdf"
```


## Trabajo a Futuro

Entrenar YOLOv8 multicampo para detectar zonas de:
* nombre
* CURP
* clave elector
* domicilio
* fecha de nacimiento

Implementar un modelo end-to-end tipo Donut (OCR transformer).